\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[francais]{babel}
\usepackage[top=3cm, bottom=3cm, left=2.5cm, right=2.5cm]{geometry}
\geometry{a4paper}

\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{paralist}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{verbatim}

\usepackage[output-decimal-marker={,}]{siunitx}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{appendix}
\usepackage{url}
\graphicspath{{figures/}}

\newcommand\cplot{\texttt{plot}}
\newcommand\cstairs{\texttt{stairs}}
\newcommand\SIi{\SI[separate-uncertainty]}
\renewcommand\tt\texttt

\title{Design d'un network on chip}

\begin{document}
\maketitle

\section{Objectifs}

Les besoins croissants en bande passante expliquent le recours
aux technologies Network On Chip. En effet, les réseaux sur puce offrent des
services plus étendus que les architectures à base de bus.


Dans le cadre général, la conception d'un réseau de communication commence
par la définition d'un modèle de communication. Dans notre cas, il s'agit de 32
processeurs qui cherchent à communiquer de manière indifférenciée à 4 mémoires
DDR2. Le sujet propose de diviser le réseau en deux sous-réseaux : une pour les
communications des processeurs vers les mémoires (requêtes) et un autre pour les
communication des mémoires vers les processeurs (réponses). Nous avons suivi
cette proposition et nous sommes intéressés au premier sous réseau.

Selon le cahier des charge, le réseau doit aussi :
\begin{itemize}
  \item garantir un débit de 100 Mbits/s pour chaque processeur,
  \item garantir une latence maximale de 80 ns point à point,
  \item permettre de configurer le réseau pour pouvoir utiliser différentes
    politiques d'arbitrage.
\end{itemize}

\section{Architecture - Modélisation SystemC}

Cette section décrit la modélisation du système en SystemC.

\subsection{Génération du traffic}

Les paquets se présentent sous la forme suivante:
\begin{itemize}
  \item 32 bits (\texttt{int data}) de donnée.
  \item 8 bits (\texttt{uint8\_t address}) d'adresse.
  \item Un champ libre (\texttt{mutable void* extra}) qui permet de rajouter de
    données de contexte suivant ce que l'on veut faire (tracing, statistics,
    \ldots). Celui ci est rempli à différents endroits stratégiques
    (générateur de trafic, routeur) par des callbacks fournis aux instances
    concernées.
\end{itemize}

\vspace{0.5cm}

Les générateurs de trafic implémentés héritent tous d'un base
\texttt{noc::abstract\_traffic\_generator} qui leur permet :
\begin{itemize}
  \item D'émettre un paquet aléatoire : \texttt{void
    emit\_random\_package(void)}. Cette fonction remplit le champs \texttt{data}
    par une donnée aléatoire. En revanche entre deux appels, le champ
    \texttt{addresse} fournit reste la même pendant une certaine durée, qui elle
    est aléatoire. Ceci permet de simuler un trafic réaliste.
  \item De pourvoir un callback de type
    \texttt{std::function<void(noc::packet)>} qui sera appelé à la création de
    chaque paquet.
\end{itemize}


\subsection{Routeur}
Nous faisons correspondre à chaque entrée du système un module routeur, connecté à autant de FIFO qu'il y a de sorties au système.
Chacun de ces modules reçoit alors les données correspondant à son entrée en suivant un protocole de synchronisation.

Sur un front montant de l'horloge, si le signal d'activation a une valeur positive,
le routeur lit un paquet et détermine la FIFO dans laquelle celui-ci doit être placé.
Le routeur lit ensuite le nombre d'emplacements libres de cette FIFO.
Si ce nombre est non nul, le paquet peut être écrit dans la FIFO.
Sinon, le routeur attend que la FIFO se désemplisse.
Une fois le paquet écrit dans la FIFO, le routeur émet un signal d'acquittement,
puis attend que le signal d'activation reprenne une valeur négative.
Une nouvelle valeur pourra alors être reçue suivant le même protocole.

\subsection{Arbitrage}
Similairement, nous faisons correspondre à chaque sortie du système un module d'arbitrage, connecté à autant de FIFO qu'il y a d'entrées au système.
Chacun de ces modules reçoit également en entrée un signal définissant un choix de stratégie d'arbitrage, déterminant dans quel ordre les paquets en provenance des différentes entrées doivent être écrites en sortie.

Dans la mesure où le choix de stratégie d'arbitrage peut changer à tout moment,
l'abitrage se fait en 5 temps:
\begin{enumerate}
\item lecture du choix de stratégie d'arbitrage,
\item détermination de la FIFO sur laquelle lire le paquet (suivant la stratégie d'arbitrage choisie),
\item lecture du paquet dans la FIFO correspondante (s'il y a au moins une FIFO non vide),
\item écriture du paquet en sortie (ou d'une valeur par défaut si toutes les FIFO sont vides),
\item et mise à jour de l'état interne du module en vue d'arbitrages futurs.
\end{enumerate}

La suite de cette partie détaille les différentes stratégies d'arbitrage modélisées et leur mise en oeuvre.

\subsubsection{Arbitrage suivant des priorités fixes}
Il s'agit de la stratégie d'arbitrage la plus simple: choisir la FIFO non vide la plus prioritaire.

Pour chaque FIFO, en suivant un ordre déterminé, le module lit donc le signal correspondant au nombre de paquets disponibles.
La première FIFO non vide est alors choisie.

\subsubsection{Arbitrage en tourniquet}
Il s'agit d'une stratégie assez similaires à la précédente.
Le module choisit ici aussi la première FIFO non vide, en parcourant celles-ci dans un ordre déterminé,
mais cette fois il les parcourt à partir de la dernière FIFO lue.

Cette stratégie d'arbitrage nécessite de savoir à tout instant quelle est la dernière FIFO à avoir été lue.
Il faut donc stocker cette information et la mettre à jour après chaque lecture.

\subsubsection{Arbitrage par choix de la moins récente utilisation}
Il s'agit cette fois de choisir la FIFO la moins récemment choisie.

La mise en oeuvre de cette stratégie repose sur l'utilisation d'un registre interne
dans lequel on stocke les indices des FIFOS par date de dernière utilisation, de la moins récente à la plus récente.
Le module  choisit alors la première FIFO non vide, en parcourant celles-ci dans l'ordre où leurs indices sont stockés dans le registre.

Après une lecture, pour mettre à jour le registre, on décale vers le début de celui-ci toutes les valeurs situées après celle correspondant à l'indice de la FIFO lue.
Cette dernière est ensuite écrite dans la dernière case du registre.

\subsubsection{Arbitrage de type FIFO}
Cette stratégie d'arbitrage est la plus complexe de celles présentées ici:
les paquets doivent être lus dans leur ordre d'arrivée, quelle que soit
la FIFO dans laquelle ils ont été placés.

Pour arriver à ce résultat, le module utilise un registre interne, initialement vide.
A chaque fois qu'une variable est écrite dans une des FIFOs, l'indice de cette FIFO est écrit dans ce registre
à une position correspondant au nombre de paquets présents dans l'ensemble des FIFOs.
Inversement, à chaque fois qu'un paquet est lu dans une FIFO, la première occurence de l'indice de cette
variable dans le registre est supprimée. Les valeurs du registres situées après cette occurence sont ensuite décalées vers le début du registre.

Ainsi, la première case du registre correspond toujours à l'indice de la FIFO contenant le paquet le plus ancien.

\subsubsection{Arbitrage aléatoire}
Pour choisir aléatoirement une FIFO dans laquelle lire, le module génère des nombres aléatoires
à l'aide d'un registre à décalage à rétroaction linéaire.
Ce nombre est ensuite ramené entre 0 et le nombre de FIFOs non vides, ce qui indique laquelle d'entre elles doit être choisie.

\section{Implémentation}

Cette section décrit un premier jet d'implémentation visant à déterminer un ordre de grandeur des performances atteignables et de la complexité du système.

\subsection{Protocole}
La communication entre les composants se fait par un protocole à deux phases. Deux fils (requête et acquittement) sont ajoutés au bus de données. Si ils sont au même niveau logique, le bus est considéré comme vide, sinon, il y a une donnée dessus. Ce protocole présente le désavantage de ne pas permettre de transmettre plus d'une donnée tous les deux cycles. En revanche, la conception de la FIFO est simplifiée.

\subsection{FIFO}
Un étage de la FIFO est composé d'un banc de registre contenant au plus une donnée. On ajoute deux bascules contrôlant respectivement le fil de requête de cet étage et le fil d'acquittement du fil de l'étage précédent. Sur un front montant i l'étage précédent est plein et le présent est vide, le banc de registre copie la donnée et change l'état des bascules de contrôle. L'étage précédent est maintenant vide et l'étage actuel est plein.
Une FIFO est composée d'une succession, éventuellement vide, d'étages.

\subsection{Arbitre}
On utilise un codage one-hot pour désigner l'indice de la FIFO choisie. l'indice $-1$ est codé par "$0\dots0$"
\paragraph{Aléatoire}
L'implémentation reprend le code SystemC. L'indice de la FIFO choisie est extrait sous forme binaire et converti. L'indice choisi est renouvellé à chaque coup d'horloge.
\paragraph{Priorité fixe}
Un indice est choisi si et seulement si la FIFO correspondant n'est pas vide et aucun des indice plus prioritaire n'est choisi.
\paragraph{LRU}
les indices sont stockés du moins récemment utilisé au plus récemment utilisé. L'indice en tête est choisi. Pour la mise à jour, un indice progresse d'une case vers le moins récemment utilisé si l'indice réellement choisi a été moins récemment utilisé.
\paragraph{Priorité tournante}
L'arbitre stocke le dernier indice utilisé et accorde la priorité au suivant. Un indice est choisi si et sulement si il n'est pas vide et il est prioritaire ou alors le précédent est prioritaire et vide ou alors le précesseur du précédent est prioritaire ou vide\ldots
\paragraph{FIFO} Non implémenté.


\subsection{Routeur}

Pour chaque donnée reçue, le routeur décode l'adresse et inverse le bit de requête de la sortie correspondante. Les bits d'acquittements sont simplement aggrégé par des porte XOR et les données sont dirigées vers toutes les sorties.

\subsection{Performance et coût}

\subsubsection{Ressources logiques}
Le tableau \ref{perfs-sw-4} montre les ressources utilisées par un switch 4 vers 1 sur un FPGA Cyclone II. On remarque d'une part qu'en terme de ressources, les FIFOs sont rapidement les plus coûteuses (il y a quatre FIFO par switch et chaque étage a une largeur de $40+2$ bits). Ainsi, chaque étage de FIFO dans les switchs 8 vers 4 coûte $32*164=5248$ registres. Pour les switchs 4 vers 1, un étage n'utilise que 656 registres. Au total, le réseau complet avec des FIFOs de longueur 8 utilise de l'ordre de 50 000 registres.

Cela n'est pas bloquant pour une utilisation ou une émulation sur FPGA. Le nombre d'entrée/sorties (1600) est beaucoup plus gênant.

\begin{table}
\centering
\begin{tabular}{|c|c|c|}
\hline
Nombre d'étages de la fifo & Nombre de registres & Nombre de blocs logiques \\
\hline
0 & 93 & 181 \\
8 & 1405 & 258 \\
16 &  2717 & 312 \\
32 & 5341 & 452 \\
\hline \hline
éléments par étages & 164 & 8 \\
autres éléments & 93 & 184 \\
\hline
\end{tabular}
\caption{Ressources requises sur un Cyclone II par un switch 4 vers 1 selon la taille des FIFOs}
\label{perfs-sw-4}
\end{table}

\subsubsection{Débit et latence}
\`A cause du protocole, le débit maximal du circuit est limité à 1 élément par entrée/sortie par 2 cycles d'horloge.

La latence minimum d'une FIFO de $N$ étages varie de $N$ cycles si la FIFO est vide à $2N$ si elle est pleine. Le routeur ajoute un cycle de latence et la sortie aussi. Finalement, la latence d'un switch est comprise entre $N+2$ et $2N+2$.

\subsubsection{Fréquence d'horloge}
Compte tenu du cahier des charges, nous évaluons surtout la qualité de l'implémentation par sa fréquence d'horloge maximale. Le réseau entier étant trop gros (en terme d'entrées/sorties) pour les FPGAs Xilinx, nous n'avons pu que synthétiser, placer et router des morceaux du réseau. Nous supposons ensuite que, les interconnexions étant simples et les contraintes de placement pas trop fortes, la performance générale serait obtenue en gardant la moins bonne performance.

Nous nous sommes intéressés aux switchs. Pour les switchs 4 vers 1, la fréquence maximale est de 180 MHz pour un FPGA Virtex 5 (XC5VFX70T). Pour les switchs 8 vers 4, la fréquence maximale est de 100 MHz sur un Virtex 5 et 170 MHz sur un Virtex 7. Le chemin critique part de la sortie de FIFOs, passe par la logique de choix des arbitreurs, le multiplexeur de ces choix, le multiplexeur vers les données de sorties et arrive sur la bascule de sortie. Nous n'avons pas eu le temps de découper ce chemin. C'est en théorie possible car les arbitreurs n'ont à faire des choix que un cycle sur deux. Pour des ASICs, on peut s'attendre, selon la technologie de fabrication, à une multiplication de la fréquence par au moins 3. Néanmoins, nous n'avons pas pu synthétiser notre circuit vers un ASIC.

\section{Méthodologie}

D'abord, il opportun de rappeler que ce projet a pour vocation de nous sensibiliser à la conception des MPOC pour une application donnée et dans un contexte donné. Mème si on a été amenés à concevoir une architecture symètrique, l'un des objectifs de ce module est de se démarquer de cette vision esthétique des systèmes on chip qui pousse à envisager des matrices régulières de communication et donc des architectures régulières.

\subsection{Contraintes}

La conception se réalise par rapport à un espace de contraintes <Q,R,T>.

Q designe les contraintes de qualité de service. Le modèle de communication à satisfaire est une communication indifférenciée des processeurs avec les mémoires avec des contraintes de débit et de latence.

R désigne les ressources disponibles. Dans notre cas, nous sommes 4 et disposons d'un certain nombre de machines. Au niveau des ressources logicielles, nous disposons de nombreuses copies de SystemC et une machine pour ISE (liscence d'évaluation 30 jours) et une autre pour Quartus et la chaîne Alliance.

T désigne le temps le temps de travail disponible. Nous avons totalisé environs 46 heures de travail jusqu'ici. L'utilisation de la méthodologie proposée nécessiterait probablement encore 50 heures.

\subsection{Méthodologie}

La méthodologie proposée se décompose en 4 étapes détaillées ci-dessous :
\begin{enumerate}
\item Le choix de l'espace de conception
\item Affectation des variables
\item Extraction des caratéristiques de l'implémentation
\item Simulation haut niveau et validation
\end{enumerate}

\paragraph{Choix de l'espace de conception}
Le but de cet étape est de définir les constantes et les variables qui seront utilisées dans l'exploration. Pour les constantes de conception, nous avons fixé un protocole, l'architecture des switchs et du routeur et une modèle. Les variables sont alors la taille des FIFOs et l'agencement des switchs.
 
On choisit \textit{a priori} un protocole car ce choix a une influence énorme sur les classes de composants. Si on avait plusieurs implémentations disponibles de chaque composant, le protocole aurait pu être une variable. Faute de temps et de ressources, nous avons fixé un protocole pour l'implémentation.

\paragraph{Affectation des variables}
Cette étape fixe certains paramètres. Par exemple, nous avons commencé nos simulations d'un switch 4 vers 4 avec une taille de FIFO égale à 16. Cette étape permet d'acquérir des données spécifiques à la configuration dans les deux étapes suivantes.

\paragraph{Extraction des caractéristiques de l'implémentation}
Une fois les paramètres d'architecture fixés, il faut définir une implémentation. L'implémentation doit fournir au simulateur les caractéristiques du réseau en fonction du des variables de conception. Cela peut passer par un générateur de code VHDL écrit par exemple en Perl et ensuite des scripts qui compilent ce code et extraient les contraintes d'horloge, les latences et les débits des switchs.

Dans notre cas, certains paramètres comme le débit et la latence (en cycles) peuvent être directement déterminés à partir des paramètres généraux. La fréquence d'horloge en revanche nécessite une implantation sur une technologie et une analyse de timing.

\paragraph{Simulation haut niveau et validation}
Le simulateur récupère ces informations et simule le système complet soumis au(x) modèle(s) de traffic pour obtenir des indicateurs globaux de performance. Si ceux-ci sont satisfaisant, on s'arrête. Sinon, on reprend l'étape 2.

On peut se poser deux question :
\begin{itemize}
\item Comment choisir les nouveau paramètres ? Ici, on peut trouver des relations mathématiques et en déduire une direction de changement. Dans le cas général, plus complexe, il est probable que l'exploration se fasse un peu en aveugle ou avec un apprentissage au fur et à mesure.
\item Et si on y arrive pas ? Il faut peut être choisir à nouveau les constantes si certaines peuvent être changée. Cela implique forcément un nouvel effort de conception d'implémentation. Cet indéterminisme dans la conception est malheureusement nécessaire.
\end{itemize}

\section{Réflexion}

cette section décrit quelques réflexions provoquées par ce cours.

\subsection{Conception}

Actuellement, on assiste à une véritable explosion du marché des systèmes temps
réel.Toutes les nouvelles cartes sont équipées de coupleurs Ethernet pour les
accès Internet. L'utilisation des systèmes temps réel embarqués avec un accès
réseau est maintenant très répandue dans plusieurs domaines, notamment les 
télécommunications, les automatismes industriels, l'industrie de l’automobile,
etc. La taille de la partie logicielle de ces dispositifs est de plus en plus
importante. Elle représente une contrainte très significative sur les ressources
qui sont, par essence, comptées.

Devant cette évolution vertigineuse, l'ingénierie, sous ses différents domaines,
paraît l'élément clé du processus de conception. La collaboration entre les
différentes disciplines, assurée par une approche ingénierie système, a permis
de mettre au point des solutions aux demandes industrielles les plus complexes.

La solution générée peut répondre aux cahier des charges certes, mais est elle
efficace ?

\subsection{Front de Pareto}

D'abord, pour la conception d'un système complexe qui met en jeu plusieurs
disciplines, l'optimisation est multi-objectifs et l'optimum global n'existe
pas. L'espace des possibles est divisé en deux familles de solutions :
\begin{itemize}
\item les solutions uniformément améliorables : une solution de cette famille
peut être améliorée suivant un critère sans qu'aucun autre critère ne soit
détérioré.
\item les solutions non uniformément améliorables : une solution de cette
famille ne peut être améliorée suivant un ou plusieurs critères sans détériorer
au moins un des autres critères. Ces solution forment la frontière de Pareto.
\end{itemize}

Pour des produits complexes, il est possible que les processus de conception ne
permettent pas d'atteindre un optimum (de Pareto). La concurrence et l'évolution
des technologies, par exemple dans le domaine des semi conducteurs, forcera les
industries à transiter vers une nouvelle ère de conception. Cette ère sera
caractérisée par un certain degrés d'automatisation du processus de conception
qui limitera les biais apportés par le concepteur humain.

\subsection{Outils de CAO}

Pour simuler la fatigue au niveau de la structure mécanique d'un drone un
ingénieur peut utiliser des outils tels que CATIA. Pour analyser
temporellement un modèle de réseau embarqué son coéquipier utilisera VNA MENTOR
GRAPHICS. Pour modéliser un circuit électronique, il existe aussi de très
nombreux outils.

On peut alors penser la conception comme un ensemble de contraintes définies au
moyen de l'ingénierie système. Les contraintes sont ensuite réparties en
domaines. Pour chaque domaine, la conception s'effectue avec des outils
spécifiques. Dans ce scénario et pour chaque discipline l'ingénieur utilise une
interface graphique ou un environnement pour décrire son modèle et le simuler.
L'optimisation reste locale à ce modèle. Jusqu'à quel point peut-on se contenter
de la somme des optimisations locales ?

L’auto-génération de code ou l’auto-conception à partir des spécifications
fixées dans le cahier des charges est donc importante. On peut distinguer deux
approches : d'un côté, un algorithme qui part d’une architecture réalisée
arbitrairement et, à chaque itération réalise les modifications sur
l’architecture en minimisant un ou plusieurs coûts donnés, de l'autre côté, un
algorithme qui transforme un ensemble de contraintes en une architecture qui
les respecte.

~

Illustrons ceci avec un exemple. Une entreprise veut concevoir un produit qui
contiendra un réseau embarqué. Ses ingénieurs disposent d'une licence VNA MENTOR
GRAPHICS. L'architecture de communication est suffisamment complexe pour qu'une
architecture choisie arbitrairement soit ne soit \textit{a priori} ni optimale
ni même respectueuse des contraintes.

Pour réaliser un outil de génération d’architecture, il faudrait utiliser 
l’interfacce import/export de VNA Mentor Graphics qui supporte FIBEX XML.
L’utilisation FIBEX parait adéquate vu qu’il s’agit d’un format XML
utilisé pour décrire des systèmes complexes de communication orientée messages.
La réalisation de l’outil revient principalement à être capable de traduire des
spécifications en entrée sous forme d’une description XML en sortie et de 
coupler cette étape à l’outil VNA. Les différentes étapes sont :
\begin{enumerate}
\item Décrire les modules demandés et une architecture de communication, qui
répond aux spécifications mais non optimale, sous VNA Mentor Graphics.
\item Exporter la description de l’architecture sous format FIBEX XML.
\item Réaliser l’étape 0 de l’algorithme d’optimisation sur la description XML.
\item Importer l’architecture par l’outil VNA Mentor Graphics.
\item Simuler l’architecture et obtenir des résultats de simulation.
\item Si résultats de simulation ne répondent pas aux objectifs de minimisation,
reprendre à l’étape 3.
\end{enumerate}

Les principales difficultés qui émergent de cet exemple sont 1) la description
initiale d'une architecture, cette étape pourrait aussi être automatisée, 2) la
convergence de l'algorithme.

~

\`A partir de cette réflexion une nouvelle vision se dégage : celle d'un
processus de conception où l'intervention de l'ingénieur est limitée par
l'automatisation de modèlisation/simulation/optimisation pour les domaines
respectifs.

Jusqu'à présent, l'innovation réside dans l'automatisation/optimisation de la
conception pour chacune des disciplines séparément. En effet, l'optimisation
pour chaque discipline pourrait prendre des contraintes qui découlent d'autres
processus de conception parallèles, mais l'amélioration ne peut porter que sur
les variables du processus en question.

\subsection{Simulation multiphysique}

Dans ce sens, il devient légitime de penser à une optimisation multi-objectifs 
et donc une simulation multiphysique. Cela est il possible?

Prenons le cas MATLAB/SIMULINK : propose une interface avec DYMOLA et avec du
code C/C++, VHDL ou SystemC. DYMOLA admet une interface avec CATIA\ldots

En somme, la simulation d'un système complet nécessite de centraliser l'accès
aux différents modèles à travers un ensemble de plug-ins. Il devient ensuite
possible d'automatiser la conception d'un système complexe en ne disposant que
du cahier des charges à l'instant de départ.

\subsection{Mur de la simulation et extraction de Modèle}

Néanmoins, cette approche d'intégration brutale n'est pas faisable. On ne peut
pas espérer simuler en un temps raisonnable ne serait ce qu'un millier de
transistors dont on aurait définit la géométrie par éléments finis et en
résolvant de manière numérique les équations différentielles thermiques et
quantiques. Plus la simulation est grande en taille, plus il faut un modèle
haut-niveau et rapide à simuler.

Il faut donc être capable d'extraire du plus bas niveau des paramètres pour les
modèles du niveau supérieur et ainsi récursivement. Cela entraîne une
déperdition d'information à mesure qu'on la synthétise, surtout en ce qui
concerne les interdépendance des paramètres. Dans le cas d'un inverseur CMOS
par exemple, si on considère dans une technologie donnée seulement la dépendance
entre la géométrie des transistors, la température et le temps de propagation,
on n'oublie la dépendance avec les tensions d'alimentation. L'analyse CEM
perd alors en précision. Néanmoins, dans cet exemple, on peut faire des
encadrements
assez précis si on limite les perturbations autorisées sur les alimentations.
Ainsi, de manière générale, la qualité d'un modèle dépend de la précision de la
prédiction des paramètres d'entrée en fonction des paramètres de sorties mais
aussi de la définition du domaine de validité du modèle.

Même si ce paradigme d'extraction de modèle permet probablement de simuler avec
précision un système, son application à l'auto-conception est mise en difficulté
par la nécessité de construire ces modèles. On peut peut-être espérer 
l'émergence de standards pour ces modèles à la manière du standard IBIS pour les
buffers d'entrée/sortie et la mise à disposition des modèles par les
fournisseurs d'IPs aux concepteurs de systèmes.

\subsection{Atteindre etrepousser le front de Pareto}

Supposons que le problème de l'auto-conception puisse se poser comme un problème
d'agencement d'un ensemble d'IPs.

Dans notre méthodologie comme dans de nombreux flots de conception présentés en
cours, la conception se fait par itérations : si le modèle ne correspond pas aux
attentes alors on l'ajuste. On est donc confronté à toutes les problématiques
d'exploration et d'optimisation en grande dimension et il faut avoir recourt aux
techniques appropriées. De manière tout à fait profane, il nous semble que le 
point clé est d'arriver à extrapoler les interdépendances des paramètres pour
déterminer la direction d'un optimum et espérer une convergence vers un point
intéressant. Le problème est que les interdépendances sont peut-être très 
chaotiques.

Même si le concepteur peut espérer concevoir un système optimal au sens de 
Pareto, il n'a pas de mécanismes à sa disposition pour repousser la frontière. 
En effet, le front de Pareto est délimité par les IPs auxquelles il a accès. 
Il peut espérer concevoir un système optimal au sens de Pareto mais n'a pas de 
mécanismes à sa disposition pour repousser la frontière. Il n'a peut-être pas la
compréhension suffisante des modèles pour discuter avec les fournisseurs d'un
nouveau composant.

On voit apparaître la nécessité d'une dynamique entre les entités que l'on a 
nommées << concepteurs >> et << fournisseurs >> pour permettre l'innovation.
Il s'agit soit d'élargir les paramètres de conception (nouvelle technologie de 
circuits intégrés par exemple) soit de rajouter une dimension (circuits 3D par 
exemple). Il semble que les concepteurs puissent communiquer leur compréhension 
de la frontière, leurs besoins pour que les fournisseurs puissent chercher des 
axes de recherche. Malheureusement, comme aucun modèle de modèle n'est parfait, 
le format de modélisation de sera peut-être pas à même d'inclure ces nouveaux 
paramètres. Il faudra donc du temps et de l'argent pour que des nouvelles 
technologies soient complétement intégrées dans les process d'auto-conception. 
On peut donc supposer que les grands groupes qui se seront établis ne seront pas
forcément moteurs dans le développement mais plutôt des intégrateurs
d'innovations provenant de plus petites structures.

\subsection{Bilan}

En résumé, la complexité des problèmes fait apparaître des frontières de Pareto. 
L'optimisation requiert un décloisonnement des domaines et l'automatisation du 
processus de conception. Une conception automatique et itérative nécessite de la
simulation multiphysique qui doit s'appuyer sur des modèles synthétiques. 
L'utilisateur des modèles dépend de ceux les maîtrisant. Une interaction est 
nécessaire pour une synergie des acteurs. Cette synergie offre des perspectives 
de dynamisme.

Il s'agit d'une présentation assez simplifiée qui correspond aux grandes lignes 
que nous avons pu distinguer dans la vision offerte jusqu'à présent par nos 
cours et nos expériences


\end{document}
